# Socio-technical Systems Cybersecurity Framework

**Authors:**
- Masike Malatji, Postgraduate School of Engineering Management, University of Johannesburg, Johannesburg, South Africa
- Sune Von Solms, Department of Electrical Engineering Science, University of Johannesburg, Johannesburg, South Africa
- Annlizé Marnewick, Postgraduate School of Engineering Management, University of Johannesburg, Johannesburg, South Africa

## Abstract

**Purpose** – This paper aims to identify and appropriately respond to any socio-technical gaps within organisational information and cybersecurity practices. This culminates in the equal emphasis of both the social, technical and environmental factors affecting security practices.

**Design/methodology/approach** – The socio-technical systems theory was used to develop a conceptual process model for analysing organisational practices in terms of their social, technical and environmental influence. The conceptual process model was then applied to specifically analyse some selected information and cybersecurity frameworks. The outcome of this exercise culminated in the design of a socio-technical systems cybersecurity framework that can be applied to any new or existing information and cybersecurity solutions in the organisation. A framework parameter to help continuously monitor the mutual alignment of the social, technical and environmental dimensions of the socio-technical systems cybersecurity framework was also introduced.

**Findings** – The results indicate a positive application of the socio-technical systems theory to the information and cybersecurity domain. In particular, the application of the conceptual process model is able to successfully categorise the selected information and cybersecurity practices into either social, technical or environmental practices. However, the validation of the socio-technical systems cybersecurity framework requires time and continuous monitoring in a real-life environment.

**Practical implications** – This research is beneficial to chief security officers, risk managers, information technology managers, security professionals and academics. They will gain more knowledge and understanding about the need to highlight the equal importance of both the social, technical and environmental dimensions of information and cybersecurity. Further, the less emphasised dimension is posited to open an equal but mutual security vulnerability gap as the more emphasised dimension. Both dimensions must, therefore, equally and jointly be emphasised for optimal security performance in the organisation.

**Originality/value** – The application of socio-technical systems theory to the information and cybersecurity domain has not received much attention. In this regard, the research adds value to the information and cybersecurity studies where too much emphasis is placed on security software and hardware capabilities.

**Keywords:** Information security, Security, Modelling

**Paper type:** Research paper

## 1. Introduction

Malicious software exploits target all sorts of network- and Internet-enabled systems such as personal devices and critical infrastructure systems to infect, damage or control the systems (Van Heerden et al., 2016). According to Al-Daraiseh et al. (2014), such cyber-crime is also on the increase. Cyber-crime includes financial fraud, stalking and blackmail (Guitton, 2013). It is thus critical to have a better understanding of relationships between technical systems and the humans who operate them as far as organisational security is concerned (Baxter and Sommerville, 2011). Systems can assume different computing formations, for example industrial control systems, weapons systems, or command, control and communication systems (Ross et al., 2016). As the National Institute of Standards and Technology (NIST) (2017a) observes, the commonality in the computing formations is that they all contain systems with complex firmware and software. Security of information in such systems is considered by Craigen et al. (2014) as the gathering and configuration of enterprise resources, processes and structures against malicious attacks. To adequately secure systems and monitor their readiness to withstand a barrage of attacks, organisations need a common framework in addition to standard controls (NIST, 2017b). Friedberg et al. (2017) argue that the implementation of such a framework should be preceded by a comprehensive analysis of security vulnerabilities and their probable impact. However, the authors caution that performing a complete security vulnerability analysis of complex systems such as an electricity grid is very complicated and completeness is hard to prove. Moreover, because each organisation's security risks are different, the tools and techniques required to achieve security outcomes will also differ (Dasso et al., 2016).

From the above arguments, it is quite evident that modern systems present even greater vulnerability challenges (Wurm et al., 2017). Examples of some of the world's most notable information and cybersecurity vulnerability exploitations include the following:

• In 2010, hackers designed the Stuxnet virus that manipulated Siemens' industrial control systems to spin the centrifuges of Iran's uranium enrichment plant to overheat (Kenney, 2015).
• In 2015, hackers managed to break into the air-traffic control systems of the United States (Hu et al., 2016).
• In 2016, cyberattacks cost United Kingdom businesses approximately £30bn. As an example, the Mirai botnet affected almost 2 500 TalkTalk routers across the United Kingdom and took 900 000 Deutsche Telekom, Germany, customers offline (Russel, 2017).
• In 2017, the WannaCry ransomware (also going by the WanaCrypt0r or WannaCrypt names) infected no less than 200 000 computers across 150 countries (Furnell and Emm, 2017).

To address these types of information and cybersecurity threats, a security framework is required to provide a common method to measure cybersecurity capabilities within an organisation (Le and Hoang, 2016). The metrics of such a framework should include a capability maturity model that incorporates not only the technical but also the social dimension of security (Carcary et al., 2016). This will enable the alignment of both the social and technical dimensions of a system and forms the fundamental tenet of socio-technical systems theory (Mumford, 2006). According to Whitworth (2009), the misalignment between the social and technical dimensions of a system is referred to as the socio-technical gap. In general, socio-technical systems (STS) theory is about an approach that seeks to optimise the alignment and correlation between the social and technical dimensions of a system, while considering the system's environment (Beekun, 1989). Organisations can themselves be thought of as complex socio-technical systems (Davis et al., 2014). Indeed, Bella et al. (2015) affirm that organisations comprise not only the software and hardware processes, but also people, physical objects and geographies. The main objective of this research is therefore:

• to develop a socio-technical systems framework to help identify and appropriately respond to any vulnerabilities that may result from the socio-technical gaps within the existing information and cybersecurity solutions

This paper is organised into six main sections. Section 1 contains this introduction and research objectives. In Section 2 the research approach used for the development of the socio-technical systems cybersecurity framework is outlined. The review of the socio-technical systems theory and the analysis of the information and cybersecurity frameworks are performed in Section 3. In addition, the socio-technical systems theory process model is developed in Section 3. The design and validation of the socio-technical systems cybersecurity conceptual framework is described in Section 4. In Section 5 the socio-technical gaps in the existing information and cybersecurity frameworks are discussed. Section 5 further recommends clear application and implementation approaches of the conceptual framework as well as suggestions on future research. The paper concludes with Section 6.

## 2. Framework Development Method

The nature and design of the proposed information and cybersecurity framework is based on the literature of the socio-technical systems theory. Figure 1 illustrates the research approach adopted in the study. As shown in the socio-technical systems cybersecurity framework (STS-CF) development methodology in Figure 1, the study demonstrates how an organisation can generate its joint optimisation security controls.

Joint optimisation simply refers to the best of both the technical and human aspects of security with equal emphasis (Emery, 1982; Mumford, 2006). The generation of the joint optimisation security controls is accomplished by analysing the existing information and cybersecurity practices within the organisation whilst at the same time categorising each output control as either social, technical or environmental. Where a security solution is found to place too much emphasis (on either the social or technical), a socio-technical gap is said to exist. The study sought to design a framework model that could help organisations attain joint optimisation by identifying and closing socio-technical gaps. These gaps equate to systems vulnerabilities that are susceptible to exploitation by cyber-attackers. At the heart of the framework is the joint optimisation process model used to analyse and categorise the existing information and cybersecurity controls. The technique used to validate the joint optimisation process model involved engagement with two industry experts. One is a cybersecurity strategist and the other a security employee within an information technology (IT) department of an organisation. The two experts were independently taken through the concept of socio-technical systems wherein a distinction between the social, technical and environmental attributes was made. Thereafter, they were asked to independently examine the information and cybersecurity framework controls, as listed in Appendix A, and classify them into either the social, technical or environmental dimension.

### Figure 1. STS-CF Development Methodology

The approach in Figure 1 consists of the following steps:

• **Analyse STS theory and develop joint optimisation process.** The socio-technical systems theory is reviewed and a high-level theoretical framework emphasising equal attention to both the social and technical dimensions is conceptualised. This is called the joint optimisation process.

• **Analyse information and cybersecurity controls through the joint optimisation process.** Although it is acknowledged that this is not an exhaustive list, the analysed controls were extracted from frequently published and industry-recognised information and cybersecurity frameworks between 2001 and 2017. This is because those frameworks will have had sufficient time to be tested and validated. An equally significant criteria is that whether these frameworks are industry-specific, governance-, risk- or even compliance-based, they must strictly have aspects of information security. Upon analysis, the purely techno-centric frameworks are regarded as having failed the joint optimisation process. That is, the socio-technical gap for justifying this research will have been found.

• **Generate STS cybersecurity controls.** Security controls analysed and iteratively passed through the joint optimisation process are compiled. In addition, duplicate controls are eliminated and similar ones combined. This culminates into new and adaptable high-level STS information and cybersecurity controls.

• **Develop STS cybersecurity controls maturity indicator model.** To measure the degree to which the implemented information and cybersecurity controls mature, an appropriate capability maturity model is developed.

• **Develop the STS-CF.** Together with the joint optimisation process, the generated security controls and capability maturity model are combined to form a conceptual STS cybersecurity framework.

• **Validate the STS-CF.** To provide proof of concept, the researchers plan to implement the proposed STS-CF in one or two organisations in South Africa to test its validity and usefulness. The results thereof will be discussed in the subsequent publication.

The next section discusses how Steps 1 through 4 are executed through the application of the socio-technical systems theory to the information and cybersecurity domain.

## 3. Literature Review

### 3.1 Socio-technical Systems Theory

#### 3.1.1 Concept Discussion

The STS theory is first analysed in this subsection. First coined by Emery and Trist, a classical socio-technical systems theory is a combination of the social and technical dimensions that are susceptible to their operating environments (Appelbaum, 1997). Socio-technical systems are distinguished by a high level of social intricacy and technical complexities intended to fulfil society's important functions (Baxter and Sommerville, 2011; Wu et al., 2015). They are the synergistic union of people, technology, organisational structures and processes, including the operating environment within which all these occur (Carayon et al., 2015). In its modern holistic view, Whitworth (2009) adds that a socio-technical system is not one of two separate and side-by-side systems, but the whole integrated system. It is the interaction between the social (including how teams and individual team members perform tasks) and technical systems (including complex interdependencies of the system development life cycle) (Troyer, 2017). Perhaps a more concise description is provided by Bostrom and Heinen (1977), and Walker et al. (2007), that STS are made up of humans applying technology solutions to execute work activities through processes within a social structure (organisation) to accomplish set goals. It should be noted that the social dimension is equally, if not more, complex even at smaller levels of groupings of people (Troyer, 2017). On the one hand, Appelbaum (1997) and Egan et al. (2004) argue that the main aim of the social dimension is to design work structures that respond to the psychological needs of the employees including taking on meaningful tasks and a sense of belonging and responsibility. On the other hand, the technical dimension is mainly concerned with the provision of tools and techniques used to accomplish organisational goals (Appelbaum, 1997; Egan et al., 2004).

In this regard, improving one dimension of a socio-technical system requires an improvement of the other for maintaining the best performance (Trist, 1981). As previously alluded to, this is called joint optimisation (Bostrom and Heinen, 1977; Appelbaum, 1997; Walker et al., 2007; Carayon et al., 2015; Oosthuizen and Pretorius, 2016). Joint optimisation is the cornerstone and foundation of the socio-technical systems theory (Chen and Redar, 2014). Although exclusively optimising either the social or technical dimension of an organisation will result in performance improvement in that specific area, researchers agree that this might lead to an overall sub-optimal STS performance (Washington and Hacker, 2000). Thus, a STS approach is more concerned with harnessing the best of both the technical and human aspects of organisational performance to accomplish the joint optimisation state (Emery, 1982; Mumford, 2006). Where the joint optimisation state lacks, a socio-technical gap exists as shown in Figure 2.

### Figure 2. Socio-technical Gap (derived from Whitworth, 2009)

Troyer (2017) has cautioned that in reality, though, the relationships between people, processes and technology is more often non-linear (complex), recursive and difficult to predict. What is not in doubt is that the STS theory represents a unique approach relating to the interrelatedness of social and technical dimensions of an organisation (Walker et al., 2007). Regardless of the complexity of organisations as complex technical and social systems, the STS theory provides a robust framework for analysis (Troyer, 2017). Oosthuizen and Pretorius (2016) agree that the STS theory can provide a good framework for modelling organisations as complex systems. Bostrom and Heinen (1977) argue that, on the one hand, the social dimension consists of:

• organisational structure; and
• actors (including people).

The technical dimension, on the other hand, comprises:

• technology; and
• work activities (tasks).

#### Table I. Social and Technical Dimensions Attributes

| **Social Dimension** | **Attributes** | **Technical Dimension** | **Attributes** |
|---------------------|----------------|------------------------|----------------|
| **Organisational structure (functions)** | Skill/ability, Values and norms, Patterns of behaviour, Culture, Knowledge, reporting/authority, Structures and control, Reward systems, Coordination needs, Policy | **Technology (tools/resources)** | Technology, Hardware, Software, Equipment, Machines, Tools, Physical security, Cybersecurity, Built environment, Information, Processes, Procedures, Techniques |
| **Actors (human beings)** | Individuals/people/humans, Teams/work groups, People relations | **Work activities (tasks)** | Activity tasks, Work organisations |
| **Environmental dimension** | | | |
| | Political, Economic, Social, Technological, Environmental, Legal, Geographical locations, Natural disasters, Built environment, Physical environment, Suppliers, Customers, Government, Other external entities | | |

*Sources: (Bostrom and Heinen, 1977; Trist, 1981; Washington and Hacker, 2000; Mumford, 2006; Davis et al., 2014; Hester, 2014; Wu et al., 2015; Oosthuizen and Pretorius, 2016; Schuetz and Schrefl, 2017)*

Table I serves as a guideline to conceptually develop the relevant attributes for both the social and technical dimensions of a socio-technical system within a complex environment. Table I shows that:

• Organisational structure constitute the social dimension enable systems of authority, communication and work flow (Hester, 2014).
• Actors are all the members of an organisation as a complex STS, including the main stakeholders who influence or perform work activities (Hester, 2014).
• Technology provides the tools and resources used in carrying out work activities (tasks) (Hester, 2014).
• Work activities are carried out within social infrastructures (Wu et al., 2015), which encompass government regulations and 'organisational structures' (Davis et al., 2014).

As already alluded to by Appelbaum (1997) and Carayon et al. (2015), an organisation, as a complex socio-technical system, is susceptible to the influence of the external environment it is embedded in (Chen and Redar, 2014). For example, a particular regulatory framework by government may greatly affect certain organisational goals (Davis et al., 2014). Table I shows attributes of the environmental dimension that can influence both the social and technical security attributes of an organisation. The environmental dimension therefore refers to the factors influencing and impacting upon a system (social and technical parts) (Appelbaum, 1997). The environmental dimension cuts-across both the social and technical dimensions.

On the one hand, there are complex political, economic, social, technological, environmental and legal factors (Schuetz and Schrefl, 2017). On the other hand, the built environment, physical environment, geographical locations and natural disasters also constitute complex environmental factors (Wu et al., 2015). To summarise Table I, human beings perform tasks using tools and resources for a specific function. Therefore, if human beings are not adequately resourced, the functions will not be performed optimally. Similarly, if the available tools and resources are in abundance but the people who use them are not adequately skilled, the functions will not be performed optimally. The entire STS must be balanced for optimal performance.

STS methods are not without criticism though. According to Mumford (2006), the failure to adopt and maintain the usage of STS approaches in, for example, the design of complex organisational systems which currently rely heavily on software-intensive systems emanates from a few challenges that must be overcome. Some of these challenges include inconsistent usage of STS terminology, perceived anachronism and analysis without synthesis (Baxter and Sommerville, 2011; Wu et al., 2015). Although the underlying STS philosophy has remained largely unchanged over the years, the specific applications and general principles have evolved over time to reflect the changing nature of technology and work practices (Davis et al., 2014). This is in contrast to Baxter and Sommerville's (2011) argument about the perceived STS theory anachronism (failure to keep up with technology trends and organisational developments). Regardless, some of the many different applications of STS thinking already include the economic, legal and regulatory, technical and security focus areas (Wu et al., 2015). Probably the most popular application of STS theory has been the development of self-regulating work groups (Appelbaum, 1997). However, the STS approach recognises the significance, as well as limitations, of group dynamics and the need to identify the complex interdependencies between the social and technical dimensions (Walker et al., 2007). In this regard, the application of the joint optimisation concept can help emphasise the significance of all the STS dimensions working in concert (Chen and Redar, 2014).

#### 3.1.2 Application of Socio-technical Systems Theory

Section 1 introduced some of the world's most recent cyber-attacks. Table II contains some of the methods adopted by cyber-attackers when pursuing a target. These cyber-attack methods are primarily concerned with access to, and compromise of, organisational information and data by unauthorised users. Being socio-technical in nature, successful information systems security design is dependent on two dimensions: humans and technology (Sabbagh and Kowalski, 2012).

Together with the social and technical dimensions shown in Table I, the humans and technology pillars are part of a four-layer information systems structure such as that in Figure 3 (Whitworth, 2009). If the top two layers are together considered social, and the bottom two technical, then (socio-technical) information systems involve all four layers. Baxter and Sommerville (2011) recommend that organisations adopt this type of STS approach to reduce the risk of systems failure. Therefore, it would be highly ineffective to simply deploy new information systems within a hierarchical control system without acknowledging the human advantages and social limitations (Walker et al., 2007). That is, the introduction of change to one part of the STS without considering how this might affect the other dimensions of a system will limit overall effectiveness (Davis et al., 2014).

#### Table II. Information and Cybersecurity Threats

| **Information and cybersecurity attack types** |
|------------------------------------------------|
| Tampering, Sensor device capture, Fake device and malicious data, Sybil attack, Source device authentication problem, Implicit deduction from sensing behaviours, Encryption leakage, Side channel attack, Insecure Web interface, Jamming, Timing attack, Replay attack, Routing threats, Hardware Trojan, Illegal hardware clones, A denial-of-service attack, Collision, Insecure cloud interface, Poor physical security, Insecure mobile interface, Selective forwarding, Wormhole attack, Hello flood, Spoofing and alternating routing information, Man-in-the-middle attacks, Insufficient security configurability, Insecure software/firmware, Authentication concerns, Data protection and recovery, Inability to deal with big data, Application layer software vulnerabilities, Data availability attacks, Lack of transport encryption, Privacy concerns, Insecure network services, Insufficient authentication and authorisation |

*Derived from Jing et al. (2014), Soomro et al., 2015, Dellios et al. (2015), Ray et al. (2016), Puthal et al. (2016), Budzak (2016), Laybats and Tredinnick (2016) and Vuorinen and Tetri (2016)*

#### Figure 3. Information System as a Socio-technical System (derived from Whitworth, 2009)

Put differently, emphasising the technical side of a socio-technical system by investing more in its practices and neglecting the social dimension, or vice versa, will not automatically translate into the optimal performance of a system (Hadid et al., 2016). This is because a socio-technical system, at least in its modern holistic view, is the entire system and not one of the dimensions of the system. Walker et al. (2007), Davis et al. (2014) and Hadid et al. (2016) all agree that optimisation of each socio-technical system element alone tends to increase not only the number of unpredictable relationships, but also the kind that negatively affects the overall system performance. Perhaps this explains why information and cybersecurity attacks have recently become increasingly successful – the existing information security practices are too technocentric (Davis et al., 2014). If the STS approaches are to be successful, however, Baxter and Sommerville (2011) caution that they must be compatible with and preserve the existing technocentric methods. In this regard, this research does not propose a stand-alone STS cybersecurity framework solution. Rather, a socio-technical systems cybersecurity framework that should be used in addition to, or in conjunction with, any industry-recognised information and cybersecurity framework is proposed. A number of methods applying the STS theory have been developed over the years as shown in Table III (Davis et al., 2014).

A comprehensive review of these methods serves to generate valuable insight that can lead to innovative methods for improving security (Carayon et al., 2015). The analyses of most of the STS models in Table III were performed by Underwood and Waterson (2012), Carayon et al. (2015) and Wu et al. (2015). It is apparent from their reviews that the vast majority of the STS approaches have been applied to the analyses of accidents and workplace safety (Wiegmann and Shappell, 2003; Underwood and Waterson, 2012; Leveson, 2004). Examples of the accidents and workplace safety models include the systems theoretic accident modelling and processes, AcciMap and human factors analysis and classification system. In comparison, the functional resonance analysis method appears to be a more generic than specialised approach. Although the functional resonance analysis method has also historically been applied to accident analysis activities (Underwood and Waterson, 2012), its developer, Hollnagel (2017) categorically discourages the notion that the functional resonance analysis method be considered an accident analysis method and/or risk assessment tool. Instead, Hollnagel (2017) recommends that the model serve as the basis for risk assessments, incidents and events investigations, or for something completely different for that matter. However, no formal validity, reliability and usability evaluation of the functional resonance analysis method has been conducted (Underwood and Waterson, 2012). As a result, the research developed a suitable STS analysis process to help categorise organisational practices into either social, technical or environmental.

#### Table III. Socio-technical Systems Models

| **STS model** | **Author/publisher** | **Year** | **Purpose** |
|---------------|---------------------|----------|-------------|
| STS theory | Trist and Bamforth, Trist, Mumford | 1951, 1981, 2006 | Originally developed to improve working conditions for employees; subsequent developments incorporated design of information systems |
| Anthropotechnology | Wisner | 1991 | To understand and resolve problems relating to technology transfer of systems to different environments |
| AcciMap | Rasmussen | 1997 | To analyse accident causes using the system-based risk management approaches |
| Interacting systems model for ergonomics | Wilson | 2000 | To understand and model human factors and ergonomics using systems thinking |
| Software-hardware-environment-liveware model | Rizzo et al. | 2000 | To proactively analyse safety issues |
| Human-systems integration | Booher | 2003 | To design and deploy complex systems through user-centred approaches |
| Human factors analysis and classification system | Wiegmann and Shappell | 2003 | To identify human causes of accidents and incidents through a process tool for investigation |
| Functional resonance analysis method | Hollnagel | 2004/2012 | To, prospectively or retrospectively, analyse how work activities occur (historically applied to accident analysis activities and used as risk assessment tool) |
| Macro-ergonomics approach | Hendrick and Kleiner, Kleiner | 2001, 2008 | To entrench macro-ergonomics techniques to work design |
| Ergonomic work analysis (activity-related ergonomics) | Montmollin, Wisner, Daniellou | 1981/1988, 1995, 2004/2006 | To improve working conditions by using employee activities as input, and to also promote productivity, quality and health |
| Model of work system | Smith and Sainfort, Carayon and Smith, Carayon | 1989, 2000, 2009 | To understand and model employee safety and well-being by using systems thinking |
| Psychodynamics of work | Dejours | 1980/2009 | To improve employee working conditions to enhance the relationship between employees and their work activities |
| Systems theoretic accident modelling and processes | Leveson | 2004, 2012 | To provide the basis for accident/incident investigations, hazard analysis, accident prevention, design for safety and safer operations |

*Source: Trist and Bamforth, 1951; Trist, 1981; Mumford, 2006; Davis et al., 2014; Carayon et al., 2015; Wu et al., 2015*

#### 3.1.3 Development of Socio-technical Systems Analysis Process

With reference to the STS-CF development methodology in Figure 1, Step 1 is completed in this subsection. According to the Merriam-Webster dictionary, optimisation refers to a methodology, process, or an act of making something (such as a system, or design) as completely effective, functional, or perfect as possible. In this regard, the research proposes an analytical tool that will help identify gaps preventing any socio-technical system from becoming as completely effective, functional, or perfect as possible. The proposed analytical tool is called the joint optimisation analysis process as shown in Figure 4.

By using Table I as a guideline, the joint optimisation analysis process is developed and operationalised as follows:

• gather (social, technical and environmental) data in the organisation;
• facilitate the classification of information into either social, technical, or environmental with participants;
• categorise data accordingly; and
• compile final report on "joint optimisation practices" as the main output/deliverable of the process.

A better understanding of how the human, social and environmental factors affect the ways in which work is performed and technical systems operated is dictated to by the outcome of the appropriate application of the STS methods (Baxter and Sommerville, 2011).

#### Figure 4. Joint Optimisation Analysis Process (derived from White and Bruton, 2011)

In the next subsection, the execution of Steps 2 and 3 of the STS-CF development methodology are discussed. In these steps, the joint optimisation process is applied to generate the socio-technical systems information and cybersecurity controls in an organisation.

#### 3.1.4 Joint Optimisation Security Controls: Application of Joint Optimisation Process

To accomplish the joint optimisation state of organisational systems security, a balanced set of social and technical controls as influenced by the external environment are required. To achieve this, the joint optimisation analysis process is used to analyse the selected information and cybersecurity frameworks presented in Table IV.

In terms of the joint optimisation analysis process' operational steps, the data gathered refers to each security control of the selected information and cybersecurity framework. Table V presents the analysis results of the frameworks. The individual security controls are listed in Appendix A per framework. Each information and cybersecurity framework control passes through the joint optimisation process as input. These inputs are then analysed by the core function of the process. The analysis results are presented in Table V as either having "Fulfilled", "Not fulfilled" or "Partially fulfilled" a dimension of the joint optimisation process. As stated previously, the joint optimisation analysis process' outputs are the actual security controls categorised into either the social, technical, or the environmental dimension of a socio-technical system.

#### Table IV. Information and Cybersecurity Frameworks

| **Information security framework** | **Author/publisher** | **Year** | **Purpose** |
|-----------------------------------|---------------------|----------|-------------|
| Systems Security Engineering Capability Maturity Model (SSE-CMM) | United States National Security Agency | 2001 | Software and systems engineering security evaluation |
| Information Security Management Systems (ISO/IEC 27002) | International Organisation for Standardisation | 2005/2013 | Recommended code of practice for information security control objectives |
| Information Technology Capability Maturity Framework (IT-CMF) | Intel Corporation | 2006 | Assessment and understanding of the organisation's information technology capability maturities |
| Information Security Maturity Model (ISM2) | NIST | 2007/2016 | Reviews and measurements of an information security posture |
| Information Security Management Maturity Model (ISM3) | ISM3 Consortium | 2007 | Resource optimisation for cyber-incidents prevention |
| ISO/IEC 21827 (Improved SSE-CMM) | International Organisation for Standardisation | 2008 | Assessment of software and systems engineering security activities as an ISO standard |
| Information Security Framework (ISF) | IBM | 2009/2013 | Analysis of information security gaps between technology and business |
| Risk Management Framework to Federal Information Systems (NIST-RMF) | NIST | 2010/2017 | Improvement of United States federal information systems platforms against cyberattacks |
| Cybersecurity Emergency Response Team Resilience Management Model (CERT-RMM) | Carnegie Mellon University | 2010/2016 | Provision of information security, operational resilience and business continuity practices |
| The Open Group Information Security Management Maturity Model (O-ISM3) | The Open Group | 2011/2017 | Alignment of organisations' business missions and security compliance requirements |
| COBIT 5.0 for Information Security | ISACA | 2012 | Control objectives for information and related technologies security model |
| National Initiative for Cybersecurity Education Cybersecurity Workforce Framework (NICE-CWF) | NIST | 2013/2014/2017 | Provides common lexicon to categorise and describe cybersecurity tasks for a workforce |
| National Initiative for Cybersecurity Education Capability Maturity Model (NICE-CMM) Version 2.0 | United States Department of Homeland Security | 2012/2014 | Provides blueprint to define cybersecurity requirements into categories |
| NIST Cybersecurity Framework (NIST-CF) | NIST | 2014/2017 | United States federal critical infrastructure cybersecurity framework |
| Core or Original Cybersecurity Capability Maturity Model (C2M2) | United States Department of Energy | 2014 | Evaluation of cybersecurity capabilities using maturity model |

As shown in Table V, only seven out of fifteen frameworks partially fulfil the security user requirements of the social dimension of a socio-technical system. The analysis further shows that all the frameworks in Table V completely fulfil the security user requirements of the technical dimension of a socio-technical system. A conclusion is drawn from these results that a socio-technical gap exists in all the analysed information and cybersecurity frameworks. Figure 2 illustrated that a socio-technical gap exists where either one of the two main STS dimensions is emphasised more than the other. This gap opens up an equal vulnerability exposure through which cyber-attacks could succeed on both STS dimensions but via the less emphasised one. This is apparent from the failures of some of the existing technical "solutions" (Davis et al., 2014).

#### Table V. Joint Optimisation Analysis Results

| **Information security framework** | **Social dimension** | **Technical dimension** |
|-----------------------------------|---------------------|------------------------|
| ISO/IEC 21827 (Improved SSE-CMM) | × | ✓✓ |
| ISO/IEC 27002 | ✓ | ✓✓ |
| IT-CMF | ✓ | ✓✓ |
| ISM2 | × | ✓✓ |
| ISM3 | × | ✓✓ |
| ISF | × | ✓✓ |
| NIST-RMF | × | ✓✓ |
| CERT-RMM | ✓ | ✓✓ |
| O-ISM3 | ✓ | ✓✓ |
| COBIT 5.0 for Information Security | ✓ | ✓✓ |
| NICE-CWF | × | ✓✓ |
| NICE-CMM | × | ✓✓ |
| NIST-CF | ✓ | ✓✓ |
| C2M2 | ✓ | ✓✓ |
| CMMI-SM | × | ✓✓ |

**Notes:** Table legend: ✓✓ Fulfilled; ✓ Partially fulfilled; × Not fulfilled

Together, the categorised output security controls are referred to as the socio-technical systems' information and cybersecurity controls (or simply joint optimisation security controls) as shown in Table VI. These were synthesised and categorised from the seven frameworks in Table V that partially fulfilled the social dimension of a socio-technical system according to the joint optimisation analysis process.

In other words, the joint optimisation security controls are the security user requirements that must be consistently met for an organisation to maintain its desired level of security capability maturity. The controls have been grouped together into four socio-technical capability domains. These capability domains were derived from the STS theory and captured in Table I already. It is worth emphasising that at this stage the security controls in Table VI are not optimised. They are just categorised according to STS capability domains.

#### Table VI. Joint Optimisation Security Controls

| **STS dimension** | **Capability domain** | **Capability-building factors (set of competency practices)** |
|-------------------|----------------------|-------------------------------------------------------------|
| **Social** | **Organisational structure** | Information and cybersecurity principles, Information and cybersecurity policy, Specific information and cybersecurity policies driven by the security competency area, Specific information security policies driven by other competency areas within the organisation, Organisational risk management committee, Organisational behaviours, Organisational leadership, Information and cybersecurity strategy, Information and cybersecurity operational plan, Organisational policies, Information and cybersecurity budget, Information and cybersecurity awareness, User access and access profile aligning with business requirements, Information and cybersecurity controls, Security roles, responsibilities and accountabilities, Information and cybersecurity communication and training, Security compliance, Personnel disciplinary process, Information systems and technology domain change control, Information and cybersecurity software development life cycle control, Information and cybersecurity measures change control, Personnel security, Cybersecurity programme strategy |
| | **Actors** | Information and cybersecurity steering committee, Chief information security officer, Information and cybersecurity manager, Information custodians/business owners, Information and cybersecurity sponsor, Stakeholders (internal), Personnel |
| **Technical** | **2.1 Technology** | Template for information and cybersecurity stakeholders, Secure development, Dashboard for information and cybersecurity, Architecture framework for security, Material for information and cybersecurity awareness, Reports for information and cybersecurity review, Reports for information and cybersecurity performance, Adequately configured and secured systems aligned with information and cybersecurity requirements and security architecture framework, Adequate protection strategy against malware, intrusion attempts and external attacks, General information and cybersecurity tools and resources, Knowledge and information management for all disciplines |
| | **2.2 Work activities** | Formulate information and cybersecurity strategy, Establish and maintain information and cybersecurity architecture, Establish information and cybersecurity governance, Develop information and cybersecurity operational plan, including risk activities, Execute information and cybersecurity operational plan, including risk activities, Identify and classify information, Assess, test and ensure information compliance, Test security in general, Manage financial resources, Manage human resources, Manage asset inventory, Manage asset configuration, Manage asset changes, Ensure information and cybersecurity business continuity, Conduct personnel security checks prior, during and upon employment termination/change, Share cybersecurity information |
| **Environment** | | Physical premises, Environmental control, Security for original equipment manufacturers, Stakeholders (internal), Security for other suppliers, Protect and manage physical environment, Manage supplier service level agreements, Ensure compliance with legal and contractual requirements, Security for physical infrastructure |

A few critical infrastructure owners have turned to maturity models to provide a framework for evaluating their security maturity capabilities (Miron and Muita, 2014). Maturity models can also be used to estimate capabilities of the perceived cyber-adversaries (Heckman et al., 2015). Better decision-making by managers has also been attributed to the utilisation maturity models in certain instances (Le and Hoang, 2016). Maturity models are closely examined in the next subsection with the aim of determining how the maturity of the derived joint optimisation security controls can be measured.

### 3.2 Security Controls Maturity Indicator Model

In this section, execution of step 4 in the STS-CF development methodology is discussed. In this step, the appropriate capability model for the measurement of the maturity of joint optimisation security controls is developed. In general, there are three types of maturity indicator models (Le and Hoang, 2016):

(1) **Progression:** Defines maturity levels as stages of achievement, e.g. human locomotion progression from crawling, walking, to running.

(2) **Capability:** Defines maturity levels as the degree to which organisational abilities have been optimised, e.g. the maturity model in Figure 5.

(3) **Hybrid:** The optimal grouping of both the capability and progression maturity models in which maturity levels express both the degree of achievement and capability.

This research was mainly concerned with measuring the degree to which an organisation can optimise its socio-technical systems security capabilities. That is, accomplish security joint optimisation capabilities. In this regard, the capability maturity model was found to be appropriate for the study. The word capability is defined by Williams (2008) as the quality of possessing the required attributes, mental or physical, for accomplishment or successful performance. Wendler (2012) views capability as the ability, whether intellectual or physical, to successfully and consistently accomplish the intended goals and objectives. On the one hand, the level of maturity of a capability indicates the degree to which practices are formalised and optimised (Heckman et al., 2015). On the other hand, a model represents a simplified representation of a system that attempts to give a detailed account of the workings of phenomena (Le and Hoang, 2016). In this regard, a capability maturity model represents an investigative tool to support the understanding and improvement of processes to, for example, achieve the desired growth and performance objectives (Carroll and Helfert, 2015).

Originating in the software development industry, capability maturity models initially represented organisational capability improvement paths for a software development process maturity (Wendler, 2012). In particular, Watts Humphrey was the first to recommend, in 1989, the utilisation of a capability maturity model to evaluate the software development process maturity (Le and Hoang, 2016). These are evaluated through different levels as shown in Figure 5.

#### Figure 5. Five-stage Process Maturity Model (derived from Heckman et al., 2015 and Le and Hoang, 2016)

| **Level 5: Optimising** | Organisation's processes are continuously improved |
|------------------------|---------------------------------------------------|
| **Level 4: Managed** | Processes are proactively defined and managed |
| **Level 3: Defined** | Processes are proactively defined |
| **Level 2: Repeatable** | Processes are reactive |
| **Level 1: Initial** | Processes are poorly defined |

Carroll and Helfert (2015) also observed that the theoretical basis for a capability maturity model is anchored around the desire to evaluate strategies for process improvement through a number of defined maturity levels which represent organisational growth. Indeed, the premise upon which capability maturity models are created is that of improvement, achieved through appraisal of internal and external organisational processes (Williams, 2008). However, capability maturity models are not without criticism. According to Williams (2008), capability maturity models are process and technology intensive, and progression from a lower to a higher level does not necessarily reflect the change process of human involvement. Thus, it is necessary to understand the structure and characteristics of a capability maturity model to investigate its possible adaptation and suitability to the socio-technical systems information and cybersecurity study. The configuration of capability maturity models is such that they comprise a structured set of elements (Wendler, 2012) that deliver a coherent blueprint to enable organisations to determine and improve their security capabilities (Heckman et al., 2015).

Essentially, the main objective of a capability maturity model is to optimise processes and practices to generate a greater return on investments (Carroll and Helfert, 2015). Table VII shows maturity indicator models of the selected information and cybersecurity frameworks. The main objective here is to use the data in Table VII to derive the appropriate and suitable capability maturity model to measure the degree to which the joint optimisation security controls are formalised and optimised.

#### Table VII. Information and Cybersecurity Capability Maturity Models

| **Capability maturity model** | **Number of levels** | **Level description** |
|------------------------------|---------------------|----------------------|
| **SSE-CMM** | 5 | Level 1: Base practices are performed informally, Level 2: Base practices are planned and tracked, Level 3: Base practices are well defined, Level 4: Base practices are controlled, Level 5: Base practices are continuously improving |
| **IT-CMF** | 5 | Level 1: Initial, Level 2: Basic, Level 3: Intermediate, Level 4: Advanced, Level 5: Optimising |
| **ISM3** | 5 | Level 1: Undefined, Level 2: Defined, Level 3: Managed, Level 4: Controlled, Level 5: Optimised |
| **ISF** | 3 | Level 1: Basic, Level 2: Proficient, Level 3: Optimised |
| **NIST** | 5 | Level 1: Policies, Level 2: Procedures, Level 3: Implementation, Level 4: Test, Level 5: Integration |
| **O-ISM3** | 5 | Level 1: Initial, Level 2: Managed, Level 3: Defined, Level 4: Controlled, Level 5: Optimised |
| **COBIT** | 6 | Level 0: Non-existent, Level 1: Initial/ad hoc, Level 2: Repeatable but intuitive, Level 3: Defined process, Level 4: Managed and measurable, Level 5: Optimised |
| **NICE-CMM** | 3 | Level 1: Limited, Level 2: Progressing, Level 3: Optimising |
| **C2M2** | 4 | MIL 0: Practices are not performed, MIL 1: Initial practices exist but may be ad hoc, MIL 2: Practices are more complete than at MIL1, MIL 3: Practices are more complete than at MIL2 |
| **US Department of Energy** | 4 | Level 0: Practices not performed, Level 1: Initial practices performed but ad hoc, Level 2: Initial institutionalisation of practices, Level 3: Institutionalised practices managed |

It has already been established that, through appraisals, the fundamental goal of a capability maturity model is to optimise organisational processes and practices (Williams, 2008; Carroll and Helfert, 2015). As shown in Table VII, the research evaluated ten capability maturity models associated with the selected information and cybersecurity frameworks. Based on the review and analysis of the ten maturity indicator models in Table VII, a six-level capability maturity model to indicate the level of maturity for each joint optimisation security control is proposed in Figure 6.

#### Figure 6. Joint Optimisation Security Controls' Maturity Indicator Model

| **Level 5: Optimising** | The socio-technical systems cybersecurity programme has been terminated and processes are embedded within daily organisational practices. In addition, the socio-technical systems information and cybersecurity practices have become fully automated and seamlessly integrated into the overall security strategy of the organisation. |
|------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Level 4: Measurable outcomes** | Proactive performance monitoring and evaluation of the socio-technical systems information and cybersecurity practices by management. Where processes appear not to be effective, mitigating actions are undertaken. Limited usage of automated tools is supplemented by continuous process improvement. |
| **Level 3: Formalised processes** | There is a formal socio-technical systems cybersecurity framework programme in place. Processes have been formally defined and documented. Policies, processes, and procedures have also been communicated through awareness and training. The procedures themselves are not yet advanced but are the mandated and formalised practices. |
| **Level 2: Basic** | Although no formal socio-technical systems cybersecurity framework processes exist. Some basic processes are being followed. However, these are followed by different business units with no standardised procedures and there is heavy reliance on the knowledge of individuals and therefore a tendency to make mistakes. |
| **Level 1: Haphazard** | The organisation has realised the need to equally emphasise the social and technical dimensions of information and cybersecurity. However, no standardised socio-technical systems cybersecurity framework processes exist; instead, there are haphazard and disorganised approaches. |
| **Level 0: Non-existent** | There is no socio-technical systems cybersecurity framework programme in place. |

With reference to Figure 6, attaining higher maturity levels only serves as a guide to effective work practices within organisations (Williams, 2008). By design, the maturity indicator model in Figure 6 makes it highly unlikely, if not impossible, for an organisation to attain a higher security capability level, say level 3, if the previous level has not been achieved.

Essentially, capability maturity evaluation models help guide organisations to assess competency practices (Carroll and Helfert, 2015). For example, these models can help improve the efficacy and maturity of critical infrastructure security controls to perfect organisational cybersecurity capabilities (Miron and Muita, 2014; Le and Hoang, 2016). In the next section, the final two steps of the STS-CF development methodology (Figure 1) are discussed. These are the final execution steps of the methodology to design, develop and validate the STS-CF.

## 4. Socio-technical Systems Cybersecurity Framework

### 4.1 STS-CF Development

Like NIST's (2017b) cybersecurity framework for critical infrastructure (Cybersecurity framework version 1.1), the STS-CF in Figure 7 was designed to complement, rather than replace, the existing cybersecurity processes and business operations. The framework is, especially, intended to provide an overarching blueprint for organisations to ensure that the existing information and cybersecurity solutions do not leave any socio-technical gaps. These gaps could be exploited by cyber-attackers with unpleasant consequences. The STS-CF consists of three major building blocks: Joint optimisation process, joint optimisation security controls and maturity indicator levels. The combined ultimate aim of the building blocks are to drive high levels of information and cybersecurity capabilities within the organisation.

#### Figure 7. Socio-technical Systems Cybersecurity Framework (derived from United States Department of Energy, 2014 and Curley et al., 2016)

#### 4.1.1 Joint Optimisation Analysis Process Building Block

This building block was described in details in subsection 3.2.2. Essentially, the joint optimisation process transforms input organisational practices, for example, security practices, into output socio-technical practices influenced by the complex environment within which they are executed. The building-block comprises of four capability domains forming the social, technical, and environmental dimensions of an organisation. Conceptually, the social dimension comprises of the organisational structure and actors, whereas the technical dimension consists of the technology and work activities. The environmental dimension cuts across both the social and technical dimensions. As developed and described mainly in Table I, the following capability domains were derived mainly from Trist (1981), Mumford (2006), Davis et al. (2014), Hester (2014), Wu et al. (2015) and Oosthuizen and Pretorius (2016):

**Organisational structure.** The purpose of the structure of the organisation is to emphasise functions executed by particular process or competency areas towards attaining security. The organisational structure components include roles and responsibilities, culture, values, communication and reporting structures.

**Actors.** The purpose of the actors in the organisation is to emphasise the role played by human beings towards attaining security. The actors include management and employees, the board and other stakeholders (internal and external) who execute or influence the way work organisational tasks are carried out.

**Technology.** The purpose of technology in the organisation is to emphasise the tools and resources used by people in carrying out work activities (competency practices or capability-building factors) towards attaining security. The technology includes any useful technical resources that can aid humans in performing their security duties, for example information, equipment, frameworks and computers.

**Work activities.** The purpose of work activities in the organisation is to emphasise the definition and execution of relevant tasks by people in different process and competency areas, using tools and resources, towards security. The work activities refer to the actual tasks and the manner in which they should be carried out.

Once the input organisational practices are fed into a transformational function that is the joint optimisation process, socio-technical systems outputs are expected on the other side. The next building-block of the STS-CF discusses how the conventional information and cybersecurity practices have been transformed into socio-technical systems cybersecurity practices.

#### 4.1.2 Joint Optimisation Security Controls Building Block

The purpose of this building block as described in subsection 3.1.4 is not to prescribe the particular security controls to be followed or as presented in Table VI. Rather, this building block merely represents the output of the security user requirements exercise embarked upon in the joint optimisation process. That is, the joint optimisation security controls will be unique for every organisation for their environmental factors vary greatly. Hence, Table VI is just an example of what the joint optimisation process outputs of an organisation could look like. Nothing more should be read from Table VI.

#### 4.1.3 Maturity Indicator Levels Building Block

The purpose of this building-block as shown in Figure 7 and described in subsection 3.2. is to determine the level of maturity for each joint optimisation security control. It is through the continuous monitoring and improvement of the joint optimisation security practices that an organisation can accomplish their desired levels of information and cybersecurity capabilities.

#### 4.1.4 Continuous Capability Improvement Outcomes Building Block

The purpose of this building block is to continuously monitor and improve the joint optimisation state of the information and cybersecurity controls. To be able to monitor this so that an organisation can determine where appropriate interventions are required, a parameter must be measured. The procedure to compute and measure such a parameter is derived from Sabiers (1998) and Washington and Hacker (2000) as follows:

Facilitate the ranking of each "joint optimisation process" output based on the perceived value of the security controls in the organisation using a Likert-type scale.

In a tabular format, aggregate the scores per STS dimension (technical, social, and environmental) using the "system equivalence" formula below:

**System equivalence = [Max. system score (social), technical, environment ≠ Min system score (social), technical, environment] / Average score (social), technical, environment**

Washington and Hacker (2000) define system equivalence as the state at which all three STS dimensions are mutually equivalent in value. In other words, the system equivalence is the parameter to measure to continuously monitor and improve the joint optimisation state of the information and cybersecurity controls. The first measurement of the parameter will form the baseline measurement. A decrease of the parameter from the baseline represents an STS cybersecurity performance improvement. Similarly, an increase in the parameter in relation to the baseline represents deterioration in cybersecurity performance and an intervention is needed urgently. Thus, an organisation improves its cybersecurity joint optimisation only when the gap between its more emphasised (best performing) and less emphasised (less performing) STS dimension is reduced (Washington and Hacker, 2000). When this is achieved, the overall performance of the STS system is improved. Furthermore, close scrutiny of the STS dimensions' individual and aggregated scores should reveal where the increase/decrease of the system equivalence parameter emanated from. This makes it relatively easy for organisations to implement appropriate interventions thereby validating the STS-CF.

### 4.2 STS-CF Validation

The task undertaken to evaluate the maturity of a technology is called technology maturity assessment, a term used by US' national aeronautics and space administration. The US' Department of Defense describes the same task as technology readiness assessment (Salim et al., 2016). According to Salim et al. (2016), the term "technology maturity" can be used interchangeably with "technology readiness". However, Tetlay and John (2009) disagree. These researchers hold a contrary view that it is both necessary and useful to consider maturity as distinct from readiness. Maturity relates to the verification of a process, system, technology, or capability against user requirements, whereas readiness has to do with the validation against user requirements within specified operating conditions (Tetlay and John, 2009). In this research, the notion that maturity (user requirements are met) and readiness (system operates according to user requirements under specified conditions) are two distinct concepts is adopted. In other words, the capability maturity model in Figure 7 is used only to verify the maturity of the implemented joint optimisation security controls.

However, the overall results of the continuous monitoring of the implemented joint optimisation security controls under specified operating conditions are intended to validate the STS-CF; that is, validate the readiness of the STS-CF. As future work, the researchers plan to validate the STS-CF through interviews with security experts in both the governmental and private sectors. Access request to conduct focus group interviews with security experts in the governmental sector has already been initiated. The researchers plan to supplement this by further interviewing security experts in the private sector. The private sector experts have also been identified through the 2017 and 2018 security summits, an annual cybersecurity event by industry in South Africa.

## 5. Discussions, Recommendations and Future Research

### 5.1 Discussions

Discussions in this paper are centred on three sub-objectives of the main research objective described in the introduction section. The first sub-objective was focused on the development of a socio-technical systems analysis process model to identify socio-technical gaps within any system. The analysis process model is called the joint optimisation process and was developed from the socio-technical systems theory. In particular, Table I was derived from the STS theory and it was out of Table I that the joint optimisation process was synthesised. To apply the joint optimisation process model for identification of socio-technical gaps in any organisational practices, data (social, technical, and environmental) should first be gathered usually in the form of a survey within the organisation. Once the data is gathered, an objective facilitator must conduct workshops to help participants classify and categorise the data into either the social, technical, or environmental dimension. The final output of this whole exercise is the joint optimisation practices in the organisation.

The main advantage of this approach is that various stakeholders in the organisation would be involved. Anything that would have fallen through the cracks had the process been performed by the information technology (IT) business unit only would be picked-up. The main disadvantage of the process, however, is potential for both technical and cognitive bias from the participants. For example, participants from the non-technical business units such as human resources, marketing and finance, would lean towards practices that are less technical and similarly participants from the more technical business units such as IT, engineering and manufacturing, would be biased towards practices that are more technical. A very strong and impartial facilitator is therefore required for this exercise. For the purposes of the study, security practices from the selected frameworks on information and cybersecurity served as the data.

The second research sub-objective was to apply the joint optimisation process to identify any socio-technical gaps to the selected information and cybersecurity framework practices. This process model can also be used to analyse other organisational practices besides information and cybersecurity practices. The results presented in Table VI are only indicative of the expected output of the application of the joint optimisation process to the information and cybersecurity framework practices. They are by no means to be interpreted as the prescribed joint optimisation security controls. Moreover, the results of such an exercise are intended to expose any existing socio-technical gaps in an organisation's current information and cybersecurity solution. The same multi-stakeholder advantages and bias disadvantages described above apply here since the process execution is the same. 

The third and final research sub-objective focused on the ultimate research goal of developing a socio-technical systems cybersecurity framework to assist organisations in closing any socio-technical gaps to their existing information and cybersecurity solutions. Together with two additional building blocks, the application of the joint optimisation process to the information and cybersecurity domain and its output culminates into the STS-CF. The two additional processes are the capability maturity indicator model as well as the continuous capability improvement outcomes. On the one hand, the capability maturity indicator reflects the degree to which organisational information and cybersecurity capabilities have been optimised on a scale from level 0 (non-existent) to level 5 (optimising). On the other hand, the continuous capability improvement outcomes measure and track a parameter called the system equivalence. The parameter is aggregated for all three STS dimensions.

### 5.2 Recommendations

As stated previously, the STS-CF was designed to complement, rather than replace, existing cybersecurity processes and business operations within organisations (NIST, 2017b). The framework should help organisations identify any cybersecurity vulnerability gaps resulting from the misalignment of the social and technical security dimensions in a complex environment. Essentially, the STS-CF is meant to serve as a complementary security model to help organisations accomplish their joint optimisation state. A perfect alignment of the four STS capability domains (structure, actors, technology, and work activities) is therefore a prerequisite for an ideal information and cybersecurity solution. Implementing such a framework will also prove to be a great challenge. The fundamental driver for the implementation of the STS-CF is an organisation's information and cybersecurity/risk management strategy. As can be seen in Figure 8, the researchers recommend how and where the STS-CF fits into the overall security programme of an organisation. According to Jairak and Praneetpolgrang (2013), the IT governance principles include information security, risk management, IT resources management, service quality, and business/IT alignment. Having developed the framework on the governance and management of enterprise IT, ISACA is also the parent company of the IT Governance Institute. In this regard, the researchers saw it fit to derive an STS-CF governance framework based on the IT Governance Institute's (2006) governance model. It is clear from Figure 8 that the STS-CF programme should not be implemented in isolation. Further, the implementation workshops begin with socio-technical user requirements exercise that generates outcomes to form the baseline cybersecurity controls. The continuous monitoring of the level of maturity for each baseline control must deliberately be pursued by management for process improvement. This should lead to security process optimisation. Where security competency practices appear not to be effective, management should further implement mitigating actions.

#### Figure 8. STS-CF Governance Framework (derived from the IT Governance Institute, 2006)

Accordingly, the researchers recommend steps 1 through 4 below only as a guideline for implementing the STS-CF. The steps were derived from the USA Department of Energy (2014) and NIST (2017b). They illustrate how an organisation can go about implementing the STS-CF to identify and close socio-technical gaps in the existing information and cybersecurity solutions. The assumption here is that an organisation already has an enterprise-wide cybersecurity/risk management strategy.

**Step 1: Requirements analysis.** The chief security officer, together with a steering committee, develop the overall cybersecurity/risk management strategy and aligns the desired socio-technical systems cybersecurity outcomes with it. This ensures that the implementation of the STS-CF does not go off on a tangent but addresses specific security requirements and strategic objective(s). At this stage, workshops are also held in the organisation to gather, identify and classify information and cybersecurity data according to the social, technical and environmental dimensions. All other relevant stakeholders are also identified at this stage.

*Deliverable: Preliminary joint optimisation security controls report.*

**Step 2: Gap analysis.** The gathered existing/new information and cybersecurity practices are analysed further. The socio-technical gaps are identified throughout the organisation. The joint optimisation security controls report is now finalised. The baseline service equivalence parameter is also computed at this stage. Intervention areas for optimisation are identified and resources pulled together. This culminates into an operational plan.

*Deliverable: Final joint optimisation security controls report; Operational plan.*

**Step 3: Prioritise and plan.** Identify initiatives/projects required to roll out the joint optimisation security operational plan. List the initiatives according to priority of execution (depending on the available budget, timeline, skilled personnel and urgency of strategic objectives). This will also inform the CSO if there is internal capacity to implement the STS-CF or if an external service provider is required. Based on the operational plan, develop the joint optimisation security action plan (s). Ensure that the action plan (s) is/are aligned with both the enterprise security and business strategies.

*Deliverable: Joint optimisation security programme action plan (s).*

**Step 4: Implement and monitor.** Execute the joint optimisation security programme action plan (s) to achieve strategic objective(s). In other words, implement the STS-CF and continuously monitor the outcomes for improvement.

*Deliverable: STS-CF outcomes and monitoring for continuous process improvement.*

Through the continuous measurement and monitoring of the STS-CF outcomes, the opportunity arises to both validate the framework and improve on its effectiveness. The results of monitoring can also assist researchers in identifying areas for future research.

### 5.3 Future Research

As the engine of the STS-CF, the joint optimisation analysis process can be applied to other domains for further security research:

• blockchain security;
• cloud computing security;
• edge computing security;
• Internet of Things security; and
• artificial intelligence security.

Furthermore, the application of linear programming to solve the joint optimisation problem as defined in this research more accurately than is currently proposed is also an opportunity for future research. Linear programming is a mathematical approach to determining a means to achieve the best possible outcome in a given situation where there are three sets of basic variables: decision variables, result variables and uncontrollable variables (Zhang et al., 2015). This approach could give rise to software that could be used for more accurate and unbiased results.

## 6. Conclusion

The literature has shown that people-centred approaches have the unique influence to inform better and holistic systems security solutions. One of the observed common themes between several security threats and vulnerabilities is that security is often treated in a piecemeal approach by different security professionals and at different times, probably using different methods dedicated at one system layer at once. The literature has shown that this opens up vulnerabilities that an attacker can exploit. The socio-technical systems security approach, which is about holistically understanding and formalising the interactions between people and systems without emphasising one aspect more than the other, was adopted by the research for a different security perspective. This perspective is called joint optimisation – an STS approach that places equal emphasis on both the social, technical, and environmental dimensions of organisational work practices. Subsequently, a socio-technical systems cybersecurity framework which consists of four major components (joint optimisation process, joint optimisation security controls, maturity indicator model, and continuous capability improvement outcomes) was developed. Finally, the steps to implement the STS-CF programme were recommended. The recommendations show how an organisation can implement the STS-CF to socio-technically optimise an existing technocentric security programme. Moreover, a governance framework on how and where the STS-CF programme fits into the overall enterprise risk and security management architecture was recommended.

---

## References

[The full reference list from the document would be included here, maintaining the academic citation format as shown in the original PDF]

---

## Appendix. Competency Practices of the Information and Cybersecurity Frameworks

[All appendix tables would be included here, maintaining their original structure and formatting]

---

*Corresponding author*  
Sune Von Solms can be contacted at: svonsolms@uj.ac.za

*For instructions on how to order reprints of this article, please visit our website:*  
www.emeraldgrouppublishing.com/licensing/reprints.htm  
*Or contact us for further details:* permissions@emeraldinsight.com